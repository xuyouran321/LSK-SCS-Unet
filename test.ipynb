{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "11.8\n",
      "8700\n",
      "2.1.0+cu118\n"
     ]
    }
   ],
   "source": [
    "#检测cuda能用吗\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda) #查看cuda\n",
    "print(torch.backends.cudnn.version()) #查看cudnn版本2.0.1\n",
    "#查看pytorch版本\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CudaDeviceProperties(name='NVIDIA GeForce RTX 3090', major=8, minor=6, total_memory=24259MB, multi_processor_count=82)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.get_device_properties(1))  # 0 表示第一个GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.603750000000005"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 85.88 + 72.34 + 72.21 + 63.87 + 66.92 + 55.76 + 37.75 + 54.10\n",
    "a/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image data/uavid/test_val/images/seq41_000000_0_4.png size: 1024 x 1024\n",
      "Image data/uavid/test_val/images/seq41_000400_0_4.png size: 1024 x 1024\n",
      "Image data/uavid/test_val/images/seq41_000500_0_4.png size: 1024 x 1024\n",
      "Image data/uavid/test_val/images/seq23_000600_0_0.png size: 1024 x 1024\n",
      "Image data/uavid/test_val/images/seq41_000700_0_4.png size: 1024 x 1024\n",
      "Image data/uavid/test_val/images/seq23_000300_0_0.png size: 1024 x 1024\n",
      "Image data/uavid/test_val/images/seq23_000900_0_4.png size: 1024 x 1024\n",
      "Image data/uavid/test_val/images/seq23_000700_0_0.png size: 1024 x 1024\n",
      "Image data/uavid/test_val/images/seq41_000800_0_4.png size: 1024 x 1024\n",
      "Image data/uavid/test_val/images/seq23_000500_0_0.png size: 1024 x 1024\n",
      "Image data/uavid/test_val/images/seq23_000400_0_0.png size: 1024 x 1024\n",
      "Image data/uavid/test_val/images/seq41_000100_0_0.png size: 1024 x 1024\n",
      "Image data/uavid/test_val/images/seq23_000100_0_0.png size: 1024 x 1024\n",
      "Image data/uavid/test_val/images/seq23_000900_0_0.png size: 1024 x 1024\n",
      "Image data/uavid/test_val/images/seq23_000200_0_0.png size: 1024 x 1024\n",
      "Image data/uavid/test_val/images/seq41_000000_0_0.png size: 1024 x 1024\n",
      "Image data/uavid/test_val/images/seq23_000000_0_0.png size: 1024 x 1024\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "# 指定图像文件夹路径\n",
    "folder_path = 'data/uavid/test_val/images'\n",
    "\n",
    "# 获取文件夹中所有图像文件的路径\n",
    "image_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "\n",
    "# 遍历每张图像文件并输出尺寸\n",
    "for image_path in image_paths:\n",
    "    # 读取图像\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    if image is not None:\n",
    "        # 获取图像尺寸\n",
    "        height, width, channels = image.shape\n",
    "        \n",
    "        # 输出图像尺寸\n",
    "        print(f\"Image {image_path} size: {width} x {height}\")\n",
    "    else:\n",
    "        print(f\"Error reading image {image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seq22_000900_0_0.png', 'seq22_000900_0_1.png', 'seq22_000900_0_2.png', 'seq22_000900_0_3.png', 'seq22_000900_0_4.png', 'seq22_000900_0_5.png', 'seq22_000900_0_6.png', 'seq22_000900_0_7.png', 'seq30_000900_0_0.png', 'seq30_000900_0_1.png', 'seq30_000900_0_2.png', 'seq30_000900_0_3.png', 'seq30_000900_0_4.png', 'seq30_000900_0_5.png', 'seq30_000900_0_6.png', 'seq30_000900_0_7.png']\n",
      "seq22000900 ['output/all/patch/seq22_000900_0_0.png', 'output/all/patch/seq22_000900_0_1.png', 'output/all/patch/seq22_000900_0_2.png', 'output/all/patch/seq22_000900_0_3.png', 'output/all/patch/seq22_000900_0_4.png', 'output/all/patch/seq22_000900_0_5.png', 'output/all/patch/seq22_000900_0_6.png', 'output/all/patch/seq22_000900_0_7.png']\n",
      "seq30000900 ['output/all/patch/seq30_000900_0_0.png', 'output/all/patch/seq30_000900_0_1.png', 'output/all/patch/seq30_000900_0_2.png', 'output/all/patch/seq30_000900_0_3.png', 'output/all/patch/seq30_000900_0_4.png', 'output/all/patch/seq30_000900_0_5.png', 'output/all/patch/seq30_000900_0_6.png', 'output/all/patch/seq30_000900_0_7.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# 定义每组图像的大小和行列数\n",
    "image_size = (1024, 1024)\n",
    "rows = 2\n",
    "columns = 4\n",
    "\n",
    "# 定义文件夹路径\n",
    "input_folder = \"output/all/patch\"\n",
    "output_folder = \"output/all/concat\"\n",
    "\n",
    "# 创建保存拼接图像的文件夹\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "def concat_images():\n",
    "    # 初始化字典来存储每组图像的名称和路径\n",
    "    image_groups = {}\n",
    "    # 获取输入文件夹中的所有图像文件并进行排序\n",
    "    image_files = sorted(os.listdir(input_folder))\n",
    "    print(image_files)\n",
    "    # 遍历图像文件列表并将图像按组存储到字典中\n",
    "    for image_file in image_files:\n",
    "        image_name = image_file.split(\"_\")[0]+image_file.split(\"_\")[1]\n",
    "        if image_name not in image_groups:\n",
    "            image_groups[image_name] = []\n",
    "        image_path = os.path.join(input_folder, image_file)\n",
    "        image_groups[image_name].append(image_path)\n",
    "    return image_groups\n",
    "\n",
    "\n",
    "# 定义函数来拼接图像\n",
    "def concatenate_images(image_paths):\n",
    "    # 创建一个空白画布来存放拼接后的图像\n",
    "    concat_image = Image.new(\"L\", (columns * image_size[0], rows * image_size[1]))\n",
    "    \n",
    "    # 遍历每张图像的路径和对应的行列位置并进行拼接\n",
    "    for i, image_path in enumerate(image_paths):\n",
    "        row = i // columns\n",
    "        column = i % columns\n",
    "        image = Image.open(image_path)\n",
    "        concat_image.paste(image, (column * image_size[0], row * image_size[1]))\n",
    "    \n",
    "    return concat_image\n",
    "\n",
    "\n",
    "image_groups = concat_images()\n",
    "for image_name, image_paths in image_groups.items():\n",
    "    print(image_name,image_paths)\n",
    "#     concat_image = concatenate_images(image_paths)\n",
    "#     output_name = image_name + \".png\"\n",
    "#     output_path = os.path.join(output_folder, output_name)\n",
    "#     concat_image.save(output_path)\n",
    "# print(\"图像拼接完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[128   0   0]\n",
      "  [128   0   0]\n",
      "  [128   0   0]\n",
      "  ...\n",
      "  [  0 128   0]\n",
      "  [  0 128   0]\n",
      "  [  0 128   0]]\n",
      "\n",
      " [[128   0   0]\n",
      "  [128   0   0]\n",
      "  [128   0   0]\n",
      "  ...\n",
      "  [  0 128   0]\n",
      "  [  0 128   0]\n",
      "  [  0 128   0]]\n",
      "\n",
      " [[128   0   0]\n",
      "  [128   0   0]\n",
      "  [128   0   0]\n",
      "  ...\n",
      "  [  0 128   0]\n",
      "  [  0 128   0]\n",
      "  [  0 128   0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[128  64 128]\n",
      "  [128  64 128]\n",
      "  [128  64 128]\n",
      "  ...\n",
      "  [128   0   0]\n",
      "  [128   0   0]\n",
      "  [128   0   0]]\n",
      "\n",
      " [[128  64 128]\n",
      "  [128  64 128]\n",
      "  [128  64 128]\n",
      "  ...\n",
      "  [128   0   0]\n",
      "  [128   0   0]\n",
      "  [128   0   0]]\n",
      "\n",
      " [[128  64 128]\n",
      "  [128  64 128]\n",
      "  [128  64 128]\n",
      "  ...\n",
      "  [128   0   0]\n",
      "  [128   0   0]\n",
      "  [128   0   0]]]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# 打开图像文件\n",
    "img = Image.open('output/all/patch/seq30_000900_0_3.png')\n",
    "\n",
    "# 将图像转换为NumPy数组\n",
    "img_array = np.array(img)\n",
    "\n",
    "# 打印数组\n",
    "print(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 512, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "class ChannelAttentionModule(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=4):\n",
    "        super(ChannelAttentionModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels // reduction, 1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels // reduction, in_channels, 1, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class SpatialAttentionModule(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttentionModule, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "# 输入 N C H W,  输出 N C H W\n",
    "if __name__ == '__main__':\n",
    "    input = torch.randn(50, 512, 7, 7)\n",
    "    se = ChannelAttentionModule(in_channels=512)\n",
    "    output = se(input)\n",
    "    print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(50, 512, 1, 1)\n",
    "se = SpatialAttentionModule()\n",
    "output = se(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (179200x7 and 512x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 79\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m7\u001b[39m)\n\u001b[1;32m     78\u001b[0m se \u001b[38;5;241m=\u001b[39m ShuffleAttention(channel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, G\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m---> 79\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/anaconda3/envs/airs/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/airs/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[21], line 69\u001b[0m, in \u001b[0;36mShuffleAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     66\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannel_shuffle(out, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# 应用全连接层将通道数从512减少到1\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mview(b, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/envs/airs/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/airs/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/airs/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (179200x7 and 512x1)"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class ShuffleAttention(nn.Module):\n",
    "    # 初始化Shuffle Attention模块\n",
    "    def __init__(self, channel=512, reduction=16, G=8):\n",
    "        super().__init__()\n",
    "        self.G = G  # 分组数量\n",
    "        self.channel = channel  # 通道数\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)  # 全局平均池化，用于生成通道注意力\n",
    "        self.gn = nn.GroupNorm(channel // (2 * G), channel // (2 * G))  # 分组归一化，用于空间注意力\n",
    "        # 以下为通道注意力和空间注意力的权重和偏置参数\n",
    "        self.cweight = Parameter(torch.zeros(1, channel // (2 * G), 1, 1))\n",
    "        self.cbias = Parameter(torch.ones(1, channel // (2 * G), 1, 1))\n",
    "        self.sweight = Parameter(torch.zeros(1, channel // (2 * G), 1, 1))\n",
    "        self.sbias = Parameter(torch.ones(1, channel // (2 * G), 1, 1))\n",
    "        self.sigmoid = nn.Sigmoid()  # Sigmoid函数，用于生成注意力图\n",
    "        self.fc = nn.Linear(channel, 1)  # 添加全连接层将通道数从512减少到1\n",
    "\n",
    "\n",
    "    # 权重初始化方法\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.normal_(m.weight, std=0.001)\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "\n",
    "    # 通道混洗方法，用于在分组处理后重组特征\n",
    "    @staticmethod\n",
    "    def channel_shuffle(x, groups):\n",
    "        b, c, h, w = x.shape\n",
    "        x = x.reshape(b, groups, -1, h, w)\n",
    "        x = x.permute(0, 2, 1, 3, 4)\n",
    "        x = x.reshape(b, -1, h, w)\n",
    "        return x\n",
    "\n",
    "    # 前向传播方法\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.size()\n",
    "        x = x.view(b * self.G, -1, h, w)  # 将输入特征图按照分组维度进行重排\n",
    "\n",
    "        x_0, x_1 = x.chunk(2, dim=1)  # 将特征图分为两部分，分别用于通道注意力和空间注意力\n",
    "\n",
    "        # 通道注意力分支\n",
    "        x_channel = self.avg_pool(x_0)  # 对第一部分应用全局平均池化\n",
    "        x_channel = self.cweight * x_channel + self.cbias  # 应用学习到的权重和偏置\n",
    "        x_channel = x_0 * self.sigmoid(x_channel)  # 通过sigmoid激活函数和原始特征图相乘，得到加权的特征图\n",
    "\n",
    "        # 空间注意力分支\n",
    "        x_spatial = self.gn(x_1)  # 对第二部分应用分组归一化\n",
    "        x_spatial = self.sweight * x_spatial + self.sbias  # 应用学习到的权重和偏置\n",
    "        x_spatial = x_1 * self.sigmoid(x_spatial)  # 通过sigmoid激活函数和原始特征图相乘，得到加权的特征图\n",
    "\n",
    "        # 将通道注意力和空间注意力的结果沿通道维度拼接\n",
    "        out = torch.cat([x_channel, x_spatial], dim=1)\n",
    "        out = out.contiguous().view(b, -1, h, w)  # 重新调整形状以匹配原始输入的维度\n",
    "\n",
    "        # 应用通道混洗，以便不同分组间的特征可以交换信息\n",
    "        out = self.channel_shuffle(out, 2)\n",
    "\n",
    "        # 应用全连接层将通道数从512减少到1\n",
    "        out = self.fc(out)\n",
    "        out = out.view(b, 1, 1, 1)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "# 输入 N C H W,  输出 N C H W\n",
    "if __name__ == '__main__':\n",
    "    input = torch.randn(50, 512, 7, 7)\n",
    "    se = ShuffleAttention(channel=512, G=4)\n",
    "    output = se(input)\n",
    "    print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [8, 7, 1, 1], expected input[50, 512, 14, 1] to have 7 channels, but got 512 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 68\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m7\u001b[39m)  \u001b[38;5;66;03m# 创建一个随机输入\u001b[39;00m\n\u001b[1;32m     67\u001b[0m block \u001b[38;5;241m=\u001b[39m CoordAtt(\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# 实例化Coordinate Attention模块\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 通过模块处理输入\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# 打印输入和输出的尺寸\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/airs/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/airs/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[28], line 50\u001b[0m, in \u001b[0;36mCoordAtt.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m x_w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool_w(x)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# 垂直方向池化并交换维度以适应拼接\u001b[39;00m\n\u001b[1;32m     49\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x_h, x_w], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# 拼接水平和垂直方向的特征\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 通过1x1卷积降维\u001b[39;00m\n\u001b[1;32m     51\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(y)  \u001b[38;5;66;03m# 批归一化\u001b[39;00m\n\u001b[1;32m     52\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(y)  \u001b[38;5;66;03m# 激活函数\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/airs/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/airs/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/airs/lib/python3.8/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/airs/lib/python3.8/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [8, 7, 1, 1], expected input[50, 512, 14, 1] to have 7 channels, but got 512 channels instead"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 定义h_sigmoid激活函数，这是一种硬Sigmoid函数\n",
    "class h_sigmoid(nn.Module):\n",
    "    def __init__(self, inplace=True):\n",
    "        super(h_sigmoid, self).__init__()\n",
    "        self.relu = nn.ReLU6(inplace=inplace)  # 使用ReLU6实现\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(x + 3) / 6  # 公式为ReLU6(x+3)/6，模拟Sigmoid激活函数\n",
    "\n",
    "# 定义h_swish激活函数，这是基于h_sigmoid的Swish函数变体\n",
    "class h_swish(nn.Module):\n",
    "    def __init__(self, inplace=True):\n",
    "        super(h_swish, self).__init__()\n",
    "        self.sigmoid = h_sigmoid(inplace=inplace)  # 使用上面定义的h_sigmoid\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.sigmoid(x)  # 公式为x * h_sigmoid(x)\n",
    "\n",
    "# 定义Coordinate Attention模块\n",
    "class CoordAtt(nn.Module):\n",
    "    def __init__(self, inp, oup, reduction=32):\n",
    "        super(CoordAtt, self).__init__()\n",
    "        # 定义水平和垂直方向的自适应平均池化\n",
    "        self.pool_h = nn.AdaptiveAvgPool2d((None, 1))  # 水平方向\n",
    "        self.pool_w = nn.AdaptiveAvgPool2d((1, None))  # 垂直方向\n",
    "\n",
    "        mip = max(8, inp // reduction)  # 计算中间层的通道数\n",
    "\n",
    "        # 1x1卷积用于降维\n",
    "        self.conv1 = nn.Conv2d(inp, mip, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(mip)  # 批归一化\n",
    "        self.act = h_swish()  # 激活函数\n",
    "\n",
    "        # 两个1x1卷积，分别对应水平和垂直方向\n",
    "        self.conv_h = nn.Conv2d(mip, oup, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv_w = nn.Conv2d(mip, oup, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x  # 保存输入作为残差连接\n",
    "\n",
    "        n, c, h, w = x.size()  # 获取输入的尺寸\n",
    "        x_h = self.pool_h(x)  # 水平方向池化\n",
    "        x_w = self.pool_w(x).permute(0, 1, 3, 2)  # 垂直方向池化并交换维度以适应拼接\n",
    "\n",
    "        y = torch.cat([x_h, x_w], dim=2)  # 拼接水平和垂直方向的特征\n",
    "        y = self.conv1(y)  # 通过1x1卷积降维\n",
    "        y = self.bn1(y)  # 批归一化\n",
    "        y = self.act(y)  # 激活函数\n",
    "\n",
    "        x_h, x_w = torch.split(y, [h, w], dim=2)  # 将特征拆分回水平和垂直方向\n",
    "        x_w = x_w.permute(0, 1, 3, 2)  # 恢复x_w的原始维度\n",
    "\n",
    "        a_h = self.conv_h(x_h).sigmoid()  # 通过1x1卷积并应用Sigmoid获取水平方向的注意力权重\n",
    "        a_w = self.conv_w(x_w).sigmoid()  # 通过1x1卷积并应用Sigmoid获取垂直方向的注意力权重\n",
    "\n",
    "        out = identity * a_w * a_h  # 应用注意力权重到输入特征，并与残差连接相乘\n",
    "\n",
    "        return out  # 返回输出\n",
    "\n",
    "# 示例使用\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    input = torch.randn(50, 512, 7, 7)  # 创建一个随机输入\n",
    "    block = CoordAtt(input.shape[2], input.shape[3])  # 实例化Coordinate Attention模块\n",
    "    output = block(input)  # 通过模块处理输入\n",
    "    print(output.shape)  # 打印输入和输出的尺寸\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(50, 512, 7, 7)  # 创建一个随机输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
